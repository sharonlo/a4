{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a4: Unrequited Mail\n",
    "====================\n",
    "\n",
    "Overall, I realized my accuracy was hard to determine features that was really accurate in determining my behavior. In the beginning, I ran some statistics on my e-mail behavior in general. I receive about 41.623 e-mails a day and respond to 2.16 of them, which is about 5% of the time. Looking back on my exchanges, I tend to only reply in pressing situations are when the conversation is still \"continuing,\" which is hard for an e-mail responder to gauge when a conversation or exchange is solved and over. My linear classifier had a cross-validation score of 0.598148103478.\n",
    "\n",
    "Overall, I turned in Mailbot for a week in which I ran a cron job every 10 min on AWS EC2 for 5 days and turned it on specifically for a whitelist of my mom, dad, and Jeff! I did not pull in new data for my calculations and trained my classifier on the existing set (thought it might cause too much of a delay).\n",
    "\n",
    "Getting Data & Storing Metadata\n",
    "-------------------------------\n",
    "For Part 1, I parsed the raw email tsv (create_csv.py) starting from the beginning of the school year (September 1, 2015) as I figured my e-mail patterns change within each school year and the ratio in which I talk to people as well. \n",
    "\n",
    "I created two hash tables: mid_all and mid_replied (each keeping the mid and metadata if all my emails, and those I just replied to). I kept them separate for faster parsing of emails I only replied to later on. \n",
    "\n",
    "In addition, I created a contact_total_count to track the number of email exchanges I have between certain contacts to later obtain a contact ratio that I will use as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PART 1:\n",
    "    #1) Parse raw email tsv, filter into mid_replied and mid_all\n",
    "    #2) Create contact_total_count, meaning # of total email exchanges between contact\n",
    "    #3) Output mid_replied and mid_all:\n",
    "    #FINAL OUTPUT:\n",
    "        #mid_all and mid_replied [TIME, RECEIVER LIST, INREPLYTO, Subj, numCC]\n",
    "    \n",
    "import csv\n",
    "from email.utils import parsedate\n",
    "from time import mktime\n",
    "from datetime import datetime\n",
    "\n",
    "contact_total_count = {} #format: K:receiver, V: #count\n",
    "\n",
    "with open('raw-email-rec.tsv', 'rb') as tsv_file:\n",
    "    tsv_reader = csv.reader(tsv_file, delimiter='\\t')\n",
    "    next(tsv_file)\n",
    "    mid_replied = {}\n",
    "    mid_all = {}\n",
    "    for row in tsv_reader:\n",
    "        if len(row) != 8 or not row[4]: #poorly formatted email or no receiver\n",
    "            continue\n",
    "        # index of all e-mails\n",
    "        m_content = []\n",
    "        mid = row[0].strip()\n",
    "        mid = mid.replace('<','')\n",
    "        mid = mid.replace('>','')\n",
    "        m_date = row[1].strip()\n",
    "        m_subj = row[2]\n",
    "        m_senders = row[3]\n",
    "        m_receivers = row[4]\n",
    "        m_numcc = len(row[5].strip().split(\",\"))\n",
    "\n",
    "        #adjust total count of contacts (sender-side)\n",
    "        sender_list = m_senders.strip().split(' ')\n",
    "        for s in sender_list:\n",
    "            s = s.strip()\n",
    "            if s in contact_total_count:\n",
    "                contact_total_count[s]+=1\n",
    "            else:\n",
    "                contact_total_count[s]=1\n",
    "        \n",
    "        #adjust total count of contacts (receiver_side)\n",
    "        receiver_list = m_receivers.strip().split(' ')\n",
    "        for r in receiver_list:\n",
    "            r = r.strip()\n",
    "            if r in contact_total_count:\n",
    "                contact_total_count[r]+=1\n",
    "            else:\n",
    "                contact_total_count[r]=1\n",
    "            \n",
    "        in_reply_to = row[6].strip()\n",
    "        time = datetime.fromtimestamp(mktime(parsedate(m_date)))\n",
    "        m_content.append(time)\n",
    "        m_content.append(receiver_list)\n",
    "        if in_reply_to: #if string is not empty, actually part of a thread  \n",
    "            m_content.append(in_reply_to)\n",
    "        else:\n",
    "            m_content.append('None')\n",
    "        m_content.append(m_subj)\n",
    "        m_content.append(m_numcc)\n",
    "        mid_all[mid] = m_content\n",
    "        \n",
    "        # I responded\n",
    "        if row[3].strip() == 'sharon_lo@brown.edu':\n",
    "            mid_replied[mid] = m_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Features for Contact Relationship\n",
    "------------------------------------------\n",
    "\n",
    "Overall, I thought that the most indicative features for whether I will reply to someone and when I will reply is the average reply time as well as my \"relationship\" with them -- something I thought could be gauged by a ratio in the # of times I reply / # of exchanges we have.\n",
    "\n",
    "These were overall documented in contact_avg_response and contact_ratio which where then used by MailBot.\n",
    "\n",
    "I later printed out my avg response time which is quite, quite high! (in milliseconds. Thus, I generally respond to individuals in 16.99 hours. The aggregate_contact_ratio takes into account the email threads I actually replied to (i.e. once I paritipate in an exchange, how likely I will continue). It does not take into account email contacts I never talked to.\n",
    "\n",
    "aggregate_avg_response:\n",
    "61166464.0344\n",
    "aggregate_contact_ratio:\n",
    "0.359973620336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate_avg_response\n",
      "61166464.0344\n",
      "aggregate_contact_ratio\n",
      "0.359973620336\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy\n",
    "import pickle\n",
    "\n",
    "#PART 2:\n",
    "        #1) Create contact_reply_times = list of response times for each contact\n",
    "        #2) Create contact_reply_count = total count of emails initiated or replied to this contact\n",
    "        #3) contact_avg_response = avg response time for each contact\n",
    "        #4) contact_ratio = #reply/#total\n",
    "        #5) write both dictionaries to file for MailBot to parse\n",
    "\n",
    "contact_reply_times = {} #format receiver: time, time, time,...\n",
    "contact_reply_count = {} #format receiver: #count\n",
    "\n",
    "for mid_key in mid_replied:\n",
    "    mid_meta= mid_replied[mid_key]\n",
    "    m_date_1 = mid_meta[0]\n",
    "    m_receiver_list = mid_meta[1]\n",
    "    m_inreplyto = mid_meta[2]\n",
    "    if m_inreplyto == 'None':\n",
    "        for r in m_receiver_list:\n",
    "            if r in contact_reply_count:\n",
    "                contact_reply_count[r]+=1\n",
    "            else:\n",
    "                contact_reply_count[r]=1\n",
    "    else: #should be in reply to something, look up in all_messages hashmap\n",
    "        in_reply_mid = mid_meta[2]\n",
    "        if in_reply_mid in mid_all.keys():\n",
    "            m_date_2 = mid_all[in_reply_mid][0]\n",
    "            diff = abs((m_date_1 - m_date_2).total_seconds())\n",
    "        else:\n",
    "            diff = 172800.0 #default value of 2 days\n",
    "        for r in m_receiver_list:\n",
    "            if r in contact_reply_count:\n",
    "                contact_reply_count[r]+=1\n",
    "            else:\n",
    "                contact_reply_count[r]=1\n",
    "            if r in contact_reply_times:\n",
    "                reply_time_list = contact_reply_times[r]\n",
    "                reply_time_list.append(diff)\n",
    "                contact_reply_times[r] = reply_time_list\n",
    "            else:\n",
    "                reply_time_list = []\n",
    "                reply_time_list.append(diff)\n",
    "                contact_reply_times[r] = reply_time_list\n",
    "\n",
    "aggregate_avg_response = 0\n",
    "num_response = 0\n",
    "#make receiver avg map\n",
    "for r in contact_reply_times.keys():\n",
    "    num_response += 1\n",
    "    time_list = numpy.array(contact_reply_times[r])\n",
    "    avg_r = numpy.mean(time_list)\n",
    "    contact_reply_times[r] = avg_r\n",
    "    aggregate_avg_response += avg_r\n",
    "\n",
    "print \"aggregate_avg_response\"\n",
    "print aggregate_avg_response\n",
    "    \n",
    "aggregate_avg_response = aggregate_avg_response/num_response\n",
    "\n",
    "#write avg_response to file:\n",
    "with open('avg_response.csv', 'wb') as avg_f:\n",
    "    csv_writer_avg = csv.writer(avg_f)\n",
    "    for key, value in contact_reply_times.items():\n",
    "        csv_writer_avg.writerow([key, value])\n",
    "\n",
    "aggregate_contact_ratio = 0\n",
    "contact_ratio = {}\n",
    "for r in contact_reply_times.keys():\n",
    "    reply_count = 0\n",
    "    if r in contact_reply_count:\n",
    "        reply_count = contact_reply_count[r] \n",
    "    ratio_r = reply_count/contact_total_count[r]\n",
    "    contact_ratio[r] = ratio_r\n",
    "    aggregate_contact_ratio += ratio_r\n",
    "\n",
    "aggregate_contact_ratio = aggregate_contact_ratio/num_response\n",
    "\n",
    "print \"aggregate_contact_ratio\"\n",
    "print aggregate_contact_ratio\n",
    "\n",
    "#write ratio to file:\n",
    "with open('contact_ratio.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for key, value in contact_ratio.items():\n",
    "        writer.writerow([key, value])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creating Entire Feature Set\n",
    "---------------------------\n",
    "\n",
    "I tried may different features but distilled down to these 6 as the most indicative of my reply time. Some others I tried out but had very negligible correlation coefficients:\n",
    "- \"ASAP\" or \"Urgent\" in body or subject of email. Turned out that this led to a lot of spam-emails or flash sales that were like \"50% off sale at ___. Be part of it asap!\"\n",
    "- emojis in body of email. I thought that this meant a more \"real\" relationship but turns out there was not much of an effect.\n",
    "\n",
    "Overall the features I used were: \n",
    "- contact ratio (# of emails replied/total exchanges)\n",
    "- average response time in past\n",
    "- day of week received\n",
    "- day of week sent reply (what time it is currently for Mailbot)\n",
    "- Time of Day (broken down into buckets for a more accurate gauge)\n",
    "    - morning, afternoon, night, late night\n",
    "- boolean: key words in email address (either a student/faculty from Brown or a company)\n",
    "- how many people cc'd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PART 3:\n",
    "#1) data_features = feature vector\n",
    "\n",
    "#features: \n",
    "    #0: contact ratio\n",
    "    #1: avg response time\n",
    "    #2: day of week received\n",
    "    #3: day of week sent, \n",
    "    #4: time of day\n",
    "    #5: boolean: certain words in email address\n",
    "    #6: how many people cc'd\n",
    "address_set = ['brown', 'google', 'microsoft', 'pinterest', 'qualtrics', 'square', 'uber', 'airbnb', 'fb', 'twitter']\n",
    "\n",
    "data_features = []\n",
    "for mid_key in mid_replied:\n",
    "    mid_meta= mid_replied[mid_key]\n",
    "    m_date_1 = mid_meta[0]\n",
    "    m_day_1= m_date_1.weekday() #where days = {0:'Mon',1:'Tues',2:'Weds',3:'Thurs',4:'Fri',5:'Sat',6:'Sun'}\n",
    "    m_day_2 = m_day_1 #update if in reply\n",
    "    \n",
    "    #categories of time-of-day {0 morning: <6 - 12, 1 afternoon: 12-6, 2 night: 6-12, 3 late night: 12 - 6 }\n",
    "    m_time = m_date_1.hour\n",
    "    if m_time >=0 and m_time < 6:\n",
    "        m_tofday = 3\n",
    "    elif m_time >=6 and m_time < 12:\n",
    "        m_tofday = 0\n",
    "    elif m_time >=12 and m_time < 18:\n",
    "        m_tofday = 1\n",
    "    else:\n",
    "        m_tofday = 2\n",
    "    \n",
    "    m_receiver_list = mid_meta[1]\n",
    "    avg_response_time = 0\n",
    "    num_receivers = len(m_receiver_list)\n",
    "    for r in m_receiver_list:\n",
    "        if r in contact_reply_times:\n",
    "            avg_response_time += contact_reply_times[r]\n",
    "        else:\n",
    "            avg_response_time += 0\n",
    "    avg_response_time = float(avg_response_time/num_receivers)\n",
    "    avg_response_time = 0.6*(aggregate_avg_response) + 0.4*(avg_response_time)\n",
    "    \n",
    "    m_address = 0\n",
    "    for r in m_receiver_list:\n",
    "        for a in address_set:\n",
    "            if a in r:\n",
    "                m_address = 1\n",
    "    \n",
    "    in_reply_mid = mid_meta[2]\n",
    "    diff = 0\n",
    "    if in_reply_mid != 'None': #should be in reply to something, look up in all_messages hashmap\n",
    "        if in_reply_mid in mid_all:\n",
    "            m_date_2 = mid_all[in_reply_mid][0]\n",
    "            m_day_2 = m_date_2.weekday()\n",
    "            diff = (m_date_1 - m_date_2).total_seconds()\n",
    "        else:\n",
    "            diff = 172800.0 #default value of 2 days, bigger than average response\n",
    "    else:  #don't include initiated emails in training set\n",
    "        continue\n",
    "    \n",
    "    ratio = 0\n",
    "    for r in m_receiver_list:\n",
    "        if r in contact_ratio:\n",
    "            ratio += contact_ratio[r]\n",
    "        else:\n",
    "            ratio += 0\n",
    "    ratio = float(ratio/num_receivers)\n",
    "    ratio = 0.8*(aggregate_contact_ratio) + 0.2*(ratio)\n",
    "    \n",
    "    m_numcc = mid_meta[4]\n",
    "    \n",
    "    #features: \n",
    "    #0: contact ratio\n",
    "    #1: avg response time\n",
    "    #2: day of week recesived\n",
    "    #3: day of week sent, \n",
    "    #4: time of day\n",
    "    #5: boolean: certain words in email address\n",
    "    #6: how many people cc'd\n",
    "    \n",
    "    mid_features = [ratio, avg_response_time, m_day_2, m_day_1, m_tofday, m_address, m_numcc, abs(diff)]\n",
    "    data_features.append(mid_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Linear Classifier\n",
    "---------------------------\n",
    "\n",
    "As stated above, my linear classifier had a score of 0.598148103478, where cross-val was much more accurate in the beginning of data (suggesting Senior Spring was extremely unpredictable, which I'm not too surprised).\n",
    "\n",
    "For me, it seemed like the most notable features were:\n",
    "- Average contact ratio\n",
    "- Time of Day\n",
    "- Whether this is someone with a notable keyword in address\n",
    "- Day of week sent and received\n",
    "\n",
    "I think some interesting directions would be able to focus more on features detecting contact relationship and time of day, as these some like the most impact predictors for me.\n",
    "\n",
    "In terms of quality of realtionship:\n",
    " - detect more features in terms of initiated_conversations with this person (how generally \"important\" is this contact to me in regards to e-mail)\n",
    "\n",
    "Time of day:\n",
    "  - differentiating more between weekends and weekdays\n",
    "    \n",
    "I also did some spot tests, which seemed like very reasonable. One instance, if I were to hypothetically have a contact where I respond 40% of our interactions, have a 4 hr avg response time, received on Monday, today is Tuesday, has a notable email address, no cc, I'm predicted to respond in 7.37391708 hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.598148103478\n",
      "[ 0.34343095  0.35275278 -2.72528618]\n",
      "\n",
      "\n",
      "coefficients: 0:ratio, 1:avg response time, 2:day received, 3:day sent, 4:time of day, 5:boolean: address part of special set, 6:numcc\n",
      "[ -3.33174879e+05   2.24788742e+00   1.28343702e+03  -8.62235434e+03\n",
      "   1.75519646e+04  -1.43057431e+04   0.00000000e+00]\n",
      "0.359973620336\n",
      "217674.249233\n",
      "\n",
      "\n",
      "I respond 40% of our interactions\n",
      "4 hr avg response time\n",
      "received on Monday, today is Tuesday\n",
      "has a notable email address\n",
      "no cc\n",
      "[ 7.37391708]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "from sklearn.externals import joblib\n",
    "import cPickle\n",
    "\n",
    "#regression\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "for data_point in data_features:\n",
    "    Xtrain.append(data_point[0:7])\n",
    "    Ytrain.append(data_point[7])\n",
    "\n",
    "lin = linear_model.Lasso()\n",
    "lin.fit(Xtrain, Ytrain)\n",
    "score = lin.score(Xtrain,Ytrain)\n",
    "print score\n",
    "print(cross_validation.cross_val_score(lin, Xtrain, Ytrain))\n",
    "\n",
    "print \"\\n\"\n",
    "print \"coefficients: 0:ratio, 1:avg response time, 2:day received, 3:day sent, 4:time of day, 5:boolean: address part of special set, 6:numcc\"\n",
    "print lin.coef_\n",
    "#predict\n",
    "\n",
    "\n",
    "with open('my_lin_classifier.pkl', 'wb') as fid:\n",
    "    cPickle.dump(lin, fid)\n",
    "\n",
    "Xtest = []\n",
    "\n",
    "print aggregate_contact_ratio\n",
    "print aggregate_avg_response\n",
    "\n",
    "print \"\\n\"\n",
    "print \"I respond 40% of our interactions\"\n",
    "print \"4 hr avg response time\"\n",
    "print \"received on Monday, today is Tuesday\"\n",
    "print \"has a notable email address\"\n",
    "print \"no cc\"\n",
    "\n",
    "Xtest.append([0.8*aggregate_contact_ratio + 0.2*(.4), 0.6*(aggregate_avg_response) + (0.4)*14400, 0, 1, 2, 1, 0])\n",
    "#Xtest.append([0.8*aggregate_contact_ratio + 0.2*0.11594202898550725, 0.6*(aggregate_avg_response) + (0.4)*57796.333333333336, 2, 3, 3, 1, 5])\n",
    "print lin.predict(Xtest)/3600\n",
    "#print linear.score(Xtest, Ytest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
